{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                                                                                                                       \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagedir = \"CG_Resized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:              CG\tNumber of images: 8394\n",
      "Label: 1\tFamily:            FOTO\tNumber of images: 8002\n",
      "Processing images ...\n",
      "Images processed: 16396\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.jpg'))  # assuming the images are stored as 'jpg'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label\n",
    "\n",
    "# Compute the features\n",
    "width, height,channels = (224,224,3)\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "list_paths = [] # List of image paths\n",
    "print(\"Processing images ...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.jpg'):\n",
    "        #print(\"[%d] Processing image: %s\" % (cnt, img_file))\n",
    "        list_paths.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = image.load_img(img_file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16396, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "Y = np_utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating base_model (ResNet50 notop)\n",
    "image_shape = (224, 224, 3)                                                                                                                                                                                                                                                                                            \n",
    "base_model = ResNet50(weights='imagenet', input_shape=image_shape, include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet50 extracted features from cg_resized-resnet50features-avgpool.npy ...\n"
     ]
    }
   ],
   "source": [
    "filename = 'cg_resized-resnet50features-avgpool.npy'\n",
    "if os.path.exists(filename):\n",
    "    print(\"Loading ResNet50 extracted features from %s ...\" %(filename))\n",
    "    resnet50features = np.load(filename)\n",
    "else:\n",
    "    print(\"Extracting features from ResNet50 layers ...\")\n",
    "    resnet50features = base_model.predict(X)\n",
    "    print(\"Saving ResNet50 extracted features into %s ...\" %(filename))\n",
    "    np.save(filename, resnet50features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16396, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create stratified k-fold subsets                                                                                                                                        \n",
    "kfold = 10  # no. of folds                                                                 \n",
    "skf = StratifiedKFold(kfold, shuffle=True,random_state=1)\n",
    "skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices\n",
    "cnt = 0                                              \n",
    "for index in skf.split(X, y):         \n",
    "    skfind[cnt] = index                                                 \n",
    "    cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Test acurracy: 0.9634\n",
      "[1] Test acurracy: 0.9732\n",
      "[2] Test acurracy: 0.9744\n",
      "[3] Test acurracy: 0.9774\n",
      "[4] Test acurracy: 0.9695\n",
      "[5] Test acurracy: 0.9756\n",
      "[6] Test acurracy: 0.9774\n",
      "[7] Test acurracy: 0.9677\n",
      "[8] Test acurracy: 0.9707\n",
      "[9] Test acurracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "# Training top_model and saving min training loss weights\n",
    "conf_mat = np.zeros((len(list_fams),len(list_fams))) # Initializing the Confusion Matrix\n",
    "for i in range(kfold):\n",
    "    train_indices = skfind[i][0]\n",
    "    test_indices = skfind[i][1]\n",
    "    X_train = resnet50features[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = resnet50features[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    top_model = svm.SVC(C=10.0,gamma=0.001)\n",
    "    top_model.fit(X_train,y_train)  # Training\n",
    "    y_pred = top_model.predict(X_test)  # Testing\n",
    "    print(\"[%d] Test acurracy: %.4f\" %(i,accuracy_score(y_test,y_pred)))\n",
    "    cm = confusion_matrix(y_test,y_pred)  # Compute confusion matrix for this fold\n",
    "    conf_mat = conf_mat + cm  # Compute global confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acurracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "# Computing the average accuracy\n",
    "avg_acc = np.trace(conf_mat)/np.sum(conf_mat)\n",
    "print(\"Average acurracy: %.4f\" %(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the confusion matrix normalized\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv/CehafLvcn5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f2fba6c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(3, 2)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(conf_mat_norm, cbar=False, annot=True, square=True,\n",
    "                 fmt='.2f', annot_kws={'size': 9}, linewidth = 0.1, cmap = 'binary',\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
